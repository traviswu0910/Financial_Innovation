{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use CNN model to classify customized candlestick pattern\n",
    "* candlestick_cnn_R08723060_Travis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, Activation, MaxPool2D\n",
    "\n",
    "\n",
    "def load_pkl(pkl_name):\n",
    "    # load data from data folder\n",
    "    with open(pkl_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def get_cnn_model(params):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(10, 10, 4)))\n",
    "    model.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(84, activation='relu'))\n",
    "    model.add(Dense(9, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def train_model(params, data):\n",
    "    model = get_cnn_model(params)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    hist = model.fit(x=data['train_gaf'], y=data['train_label_arr'],\n",
    "                     batch_size=params['batch_size'], epochs=params['epochs'], verbose=2)\n",
    "    return (model, hist)\n",
    "\n",
    "def print_result(data, model):\n",
    "    # get train & test pred-labels\n",
    "    train_pred = model.predict_classes(data['train_gaf'])\n",
    "    test_pred = model.predict_classes(data['test_gaf'])\n",
    "    # get train & test true-labels\n",
    "    train_label = data['train_label'][:, 0]\n",
    "    test_label = data['test_label'][:, 0]\n",
    "    # confusion matrix\n",
    "    train_result_cm = confusion_matrix(train_label, train_pred, labels=range(9))\n",
    "    test_result_cm = confusion_matrix(test_label, test_pred, labels=range(9))\n",
    "    print(train_result_cm, '\\n'*2, test_result_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/235 - 3s - loss: 1.5586 - accuracy: 0.4135\n",
      "Epoch 2/10\n",
      "235/235 - 3s - loss: 0.7702 - accuracy: 0.7239\n",
      "Epoch 3/10\n",
      "235/235 - 3s - loss: 0.5900 - accuracy: 0.7847\n",
      "Epoch 4/10\n",
      "235/235 - 3s - loss: 0.5247 - accuracy: 0.8091\n",
      "Epoch 5/10\n",
      "235/235 - 3s - loss: 0.4887 - accuracy: 0.8212\n",
      "Epoch 6/10\n",
      "235/235 - 3s - loss: 0.4619 - accuracy: 0.8291\n",
      "Epoch 7/10\n",
      "235/235 - 4s - loss: 0.4377 - accuracy: 0.8411\n",
      "Epoch 8/10\n",
      "235/235 - 4s - loss: 0.4195 - accuracy: 0.8448\n",
      "Epoch 9/10\n",
      "235/235 - 3s - loss: 0.4119 - accuracy: 0.8488\n",
      "Epoch 10/10\n",
      "235/235 - 3s - loss: 0.3987 - accuracy: 0.8575\n",
      "CNN test accuracy: 0.8185999989509583\n",
      "WARNING:tensorflow:From <ipython-input-1-9f6ecd1c0542>:36: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "[[2079  101  182  107  115   54   45  257   60]\n",
      " [  28 1456    0   15    0    0    0    1    0]\n",
      " [  21    0 1473    0    6    0    0    0    0]\n",
      " [  11   15    0 1072    0    0    0  402    0]\n",
      " [  39    0   42    0 1378    0    1    0   40]\n",
      " [ 115    1    0    1    0 1159    0  224    0]\n",
      " [ 264    2    6    0    4    0 1175    0   49]\n",
      " [   4    1    0   41    0    1    0 1453    0]\n",
      " [  81    0    3    0  224    0   18    0 1174]] \n",
      "\n",
      " [[686  28  79  37  36  22   9  84  19]\n",
      " [ 10 484   0   6   0   0   0   0   0]\n",
      " [  0   0 500   0   0   0   0   0   0]\n",
      " [  9   8   0 332   0   0   0 151   0]\n",
      " [ 17   0  25   0 443   0   0   0  15]\n",
      " [ 50   1   0   0   0 386   0  63   0]\n",
      " [118   0   2   0   0   0 372   0   8]\n",
      " [  3   1   0   1   0   0   0 495   0]\n",
      " [ 37   0   0   0  62   0   6   0 395]]\n"
     ]
    }
   ],
   "source": [
    "PARAMS = {}\n",
    "PARAMS['pkl_name'] = './data/label8_eurusd_10bar_1500_500_val200_gaf_culr.pkl'\n",
    "PARAMS['classes'] = 9\n",
    "PARAMS['lr'] = 0.01\n",
    "PARAMS['epochs'] = 10\n",
    "PARAMS['batch_size'] = 64\n",
    "PARAMS['optimizer'] = optimizers.SGD(lr=PARAMS['lr'])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# load data & keras model\n",
    "data = load_pkl(PARAMS['pkl_name'])\n",
    "# train cnn model\n",
    "model, hist = train_model(PARAMS, data)\n",
    "# train & test result\n",
    "scores = model.evaluate(data['test_gaf'], data['test_label_arr'], verbose=0)\n",
    "print('CNN test accuracy:', scores[1])\n",
    "print_result(data, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use LSTM model to classify customized candlestick pattern\n",
    "* candlestick_lstm_R087823060_Travis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "import keras\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pkl(pkl_name):\n",
    "    # load data from data folder\n",
    "    with open(pkl_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes):\n",
    "    x_train = x_train.reshape(-1, n_step, n_input)\n",
    "    x_test = x_test.reshape(-1, n_step, n_input)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "    return (x_train, x_test, y_train, y_test)\n",
    "\n",
    "def lstm_model(n_input, n_step, n_hidden, n_classes):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_hidden, batch_input_shape=(None, n_step, n_input), unroll=True))\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "def train_lstm(model, x_train, y_train, x_test, y_test, \n",
    "        learning_rate, training_iters, batch_size):\n",
    "    adam = Adam(lr=learning_rate)\n",
    "    model.summary()\n",
    "    model.compile(optimizer=adam,\n",
    "        loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,\n",
    "        batch_size=batch_size, epochs=training_iters,\n",
    "        verbose=1, validation_data=(x_test, y_test))\n",
    "    \n",
    "def print_result(data, x_train, x_test, model):\n",
    "    # get train & test pred-labels\n",
    "    train_pred = model.predict_classes(x_train)\n",
    "    test_pred = model.predict_classes(x_test)\n",
    "    # get train & test true-labels\n",
    "    train_label = data['train_label'][:, 0]\n",
    "    test_label = data['test_label'][:, 0]\n",
    "    # confusion matrix\n",
    "    train_result_cm = confusion_matrix(train_label, train_pred, labels=range(9))\n",
    "    test_result_cm = confusion_matrix(test_label, test_pred, labels=range(9))\n",
    "    print(train_result_cm, '\\n'*2, test_result_cm)\n",
    "    \n",
    "def mnist_lstm_main():\n",
    "    # training parameters\n",
    "    learning_rate = 0.001\n",
    "    training_iters = 150\n",
    "    batch_size = 128\n",
    "\n",
    "    # model parameters\n",
    "    n_input = 40\n",
    "    n_step = 10\n",
    "    n_hidden = 256\n",
    "    n_classes = 10\n",
    "\n",
    "    data = load_pkl('./data/label8_eurusd_10bar_1500_500_val200_gaf_culr.pkl')\n",
    "    x_train, y_train, x_test, y_test = data['train_gaf'], data['train_label'][:, 0], data['test_gaf'], data['test_label'][:, 0]\n",
    "    x_train, x_test, y_train, y_test = lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes)\n",
    "\n",
    "    model = lstm_model(n_input, n_step, n_hidden, n_classes)\n",
    "    train_lstm(model, x_train, y_train, x_test, y_test, learning_rate, \n",
    "               training_iters, batch_size)\n",
    "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('LSTM test accuracy:', scores[1])\n",
    "    print('epoch:{}'.format(training_iters))\n",
    "    print_result(data, x_train, x_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 256)               304128    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 306,698\n",
      "Trainable params: 306,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 2.0942 - accuracy: 0.2077 - val_loss: 1.7353 - val_accuracy: 0.2368\n",
      "Epoch 2/150\n",
      "118/118 [==============================] - 3s 26ms/step - loss: 1.4782 - accuracy: 0.3529 - val_loss: 1.4108 - val_accuracy: 0.3618\n",
      "Epoch 3/150\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 1.3061 - accuracy: 0.4490 - val_loss: 1.2614 - val_accuracy: 0.4596\n",
      "Epoch 4/150\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 1.0820 - accuracy: 0.5617 - val_loss: 1.0018 - val_accuracy: 0.5834\n",
      "Epoch 5/150\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.8831 - accuracy: 0.6613 - val_loss: 0.7544 - val_accuracy: 0.7190\n",
      "Epoch 6/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.7322 - accuracy: 0.7141 - val_loss: 0.8267 - val_accuracy: 0.6760\n",
      "Epoch 7/150\n",
      "118/118 [==============================] - 4s 30ms/step - loss: 0.6863 - accuracy: 0.7313 - val_loss: 0.6239 - val_accuracy: 0.7462\n",
      "Epoch 8/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.6373 - accuracy: 0.7545 - val_loss: 0.7487 - val_accuracy: 0.7004\n",
      "Epoch 9/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.6631 - accuracy: 0.7403 - val_loss: 0.5613 - val_accuracy: 0.7934\n",
      "Epoch 10/150\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 0.6087 - accuracy: 0.7623 - val_loss: 0.5054 - val_accuracy: 0.8024\n",
      "Epoch 11/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.5869 - accuracy: 0.7713 - val_loss: 0.7270 - val_accuracy: 0.7220\n",
      "Epoch 12/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.6225 - accuracy: 0.7584 - val_loss: 0.5324 - val_accuracy: 0.7990\n",
      "Epoch 13/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.5600 - accuracy: 0.7851 - val_loss: 0.5977 - val_accuracy: 0.7696\n",
      "Epoch 14/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.5766 - accuracy: 0.7785 - val_loss: 0.4940 - val_accuracy: 0.8132\n",
      "Epoch 15/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.5495 - accuracy: 0.7905 - val_loss: 0.5833 - val_accuracy: 0.7796\n",
      "Epoch 16/150\n",
      "118/118 [==============================] - 3s 30ms/step - loss: 0.5638 - accuracy: 0.7829 - val_loss: 0.4866 - val_accuracy: 0.8228\n",
      "Epoch 17/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.5723 - accuracy: 0.7792 - val_loss: 0.4998 - val_accuracy: 0.8228\n",
      "Epoch 18/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.5517 - accuracy: 0.7891 - val_loss: 0.5043 - val_accuracy: 0.8038\n",
      "Epoch 19/150\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.5335 - accuracy: 0.7949 - val_loss: 0.5042 - val_accuracy: 0.8116\n",
      "Epoch 20/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.5228 - accuracy: 0.7975 - val_loss: 0.4503 - val_accuracy: 0.8388\n",
      "Epoch 21/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.5455 - accuracy: 0.7876 - val_loss: 0.4394 - val_accuracy: 0.8426\n",
      "Epoch 22/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.5112 - accuracy: 0.8079 - val_loss: 0.4264 - val_accuracy: 0.8430\n",
      "Epoch 23/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.5081 - accuracy: 0.8095 - val_loss: 0.4553 - val_accuracy: 0.8316\n",
      "Epoch 24/150\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.5202 - accuracy: 0.8003 - val_loss: 0.4213 - val_accuracy: 0.8518\n",
      "Epoch 25/150\n",
      "118/118 [==============================] - 4s 36ms/step - loss: 0.5136 - accuracy: 0.8071 - val_loss: 0.4332 - val_accuracy: 0.8392\n",
      "Epoch 26/150\n",
      "118/118 [==============================] - 4s 35ms/step - loss: 0.5028 - accuracy: 0.8065 - val_loss: 0.4759 - val_accuracy: 0.8204\n",
      "Epoch 27/150\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.5028 - accuracy: 0.8099 - val_loss: 0.4638 - val_accuracy: 0.8292\n",
      "Epoch 28/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.4913 - accuracy: 0.8131 - val_loss: 0.3936 - val_accuracy: 0.8616\n",
      "Epoch 29/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.4734 - accuracy: 0.8195 - val_loss: 0.3805 - val_accuracy: 0.8680\n",
      "Epoch 30/150\n",
      "118/118 [==============================] - 4s 30ms/step - loss: 0.4690 - accuracy: 0.8227 - val_loss: 0.4311 - val_accuracy: 0.8366\n",
      "Epoch 31/150\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 0.4612 - accuracy: 0.8252 - val_loss: 0.3893 - val_accuracy: 0.8600\n",
      "Epoch 32/150\n",
      "118/118 [==============================] - 4s 30ms/step - loss: 0.4606 - accuracy: 0.8280 - val_loss: 0.4233 - val_accuracy: 0.8384\n",
      "Epoch 33/150\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 0.4516 - accuracy: 0.8299 - val_loss: 0.3830 - val_accuracy: 0.8608\n",
      "Epoch 34/150\n",
      "118/118 [==============================] - 4s 33ms/step - loss: 0.4415 - accuracy: 0.8351 - val_loss: 0.3852 - val_accuracy: 0.8662\n",
      "Epoch 35/150\n",
      "118/118 [==============================] - 4s 38ms/step - loss: 0.4439 - accuracy: 0.8317 - val_loss: 0.3812 - val_accuracy: 0.8642\n",
      "Epoch 36/150\n",
      "118/118 [==============================] - 4s 36ms/step - loss: 0.4491 - accuracy: 0.8290 - val_loss: 0.4032 - val_accuracy: 0.8612\n",
      "Epoch 37/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.4401 - accuracy: 0.8315 - val_loss: 0.4467 - val_accuracy: 0.8300\n",
      "Epoch 38/150\n",
      "118/118 [==============================] - 4s 30ms/step - loss: 0.4521 - accuracy: 0.8247 - val_loss: 0.4655 - val_accuracy: 0.8156\n",
      "Epoch 39/150\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 0.4362 - accuracy: 0.8332 - val_loss: 0.4250 - val_accuracy: 0.8410\n",
      "Epoch 40/150\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 0.4256 - accuracy: 0.8381 - val_loss: 0.3796 - val_accuracy: 0.8616\n",
      "Epoch 41/150\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 0.4241 - accuracy: 0.8399 - val_loss: 0.4760 - val_accuracy: 0.8218\n",
      "Epoch 42/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.4311 - accuracy: 0.8345 - val_loss: 0.3756 - val_accuracy: 0.8688\n",
      "Epoch 43/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.4295 - accuracy: 0.8351 - val_loss: 0.3938 - val_accuracy: 0.8534\n",
      "Epoch 44/150\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 0.4260 - accuracy: 0.8386 - val_loss: 0.4063 - val_accuracy: 0.8578\n",
      "Epoch 45/150\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.4257 - accuracy: 0.8393 - val_loss: 0.4072 - val_accuracy: 0.8522\n",
      "Epoch 46/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.4317 - accuracy: 0.8381 - val_loss: 0.3913 - val_accuracy: 0.8578\n",
      "Epoch 47/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.4271 - accuracy: 0.8357 - val_loss: 0.4922 - val_accuracy: 0.8230\n",
      "Epoch 48/150\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.4343 - accuracy: 0.8349 - val_loss: 0.3800 - val_accuracy: 0.8588\n",
      "Epoch 49/150\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 0.4223 - accuracy: 0.8388 - val_loss: 0.3767 - val_accuracy: 0.8672\n",
      "Epoch 50/150\n",
      "118/118 [==============================] - 4s 33ms/step - loss: 0.4270 - accuracy: 0.8372 - val_loss: 0.5119 - val_accuracy: 0.8044\n",
      "Epoch 51/150\n",
      "118/118 [==============================] - 4s 30ms/step - loss: 0.4279 - accuracy: 0.8388 - val_loss: 0.3684 - val_accuracy: 0.8666\n",
      "Epoch 52/150\n",
      "118/118 [==============================] - 4s 30ms/step - loss: 0.4131 - accuracy: 0.8426 - val_loss: 0.4791 - val_accuracy: 0.8200\n",
      "Epoch 53/150\n",
      "118/118 [==============================] - 4s 30ms/step - loss: 0.4316 - accuracy: 0.8340 - val_loss: 0.4116 - val_accuracy: 0.8506\n",
      "Epoch 54/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.4403 - accuracy: 0.8315 - val_loss: 0.3898 - val_accuracy: 0.8624\n",
      "Epoch 55/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.4119 - accuracy: 0.8453 - val_loss: 0.3575 - val_accuracy: 0.8762\n",
      "Epoch 56/150\n",
      "118/118 [==============================] - 3s 30ms/step - loss: 0.4196 - accuracy: 0.8397 - val_loss: 0.3977 - val_accuracy: 0.8570\n",
      "Epoch 57/150\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.4206 - accuracy: 0.8406 - val_loss: 0.3926 - val_accuracy: 0.8540\n",
      "Epoch 58/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.4304 - accuracy: 0.8365 - val_loss: 0.4094 - val_accuracy: 0.8488\n",
      "Epoch 59/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.4111 - accuracy: 0.8466 - val_loss: 0.5583 - val_accuracy: 0.7914\n",
      "Epoch 60/150\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 0.4148 - accuracy: 0.8424 - val_loss: 0.4347 - val_accuracy: 0.8322\n",
      "Epoch 61/150\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 0.4270 - accuracy: 0.8380 - val_loss: 0.4367 - val_accuracy: 0.8362\n",
      "Epoch 62/150\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 0.4021 - accuracy: 0.8465 - val_loss: 0.5078 - val_accuracy: 0.8120\n",
      "Epoch 63/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.4202 - accuracy: 0.8406 - val_loss: 0.4328 - val_accuracy: 0.8312\n",
      "Epoch 64/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.4081 - accuracy: 0.8424 - val_loss: 0.3606 - val_accuracy: 0.8768\n",
      "Epoch 65/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.3990 - accuracy: 0.8478 - val_loss: 0.3537 - val_accuracy: 0.8790\n",
      "Epoch 66/150\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 0.4000 - accuracy: 0.8476 - val_loss: 0.4016 - val_accuracy: 0.8548\n",
      "Epoch 67/150\n",
      "118/118 [==============================] - 4s 30ms/step - loss: 0.4037 - accuracy: 0.8479 - val_loss: 0.4328 - val_accuracy: 0.8330\n",
      "Epoch 68/150\n",
      "118/118 [==============================] - 4s 30ms/step - loss: 0.4093 - accuracy: 0.8442 - val_loss: 0.4172 - val_accuracy: 0.8506\n",
      "Epoch 69/150\n",
      "118/118 [==============================] - 4s 30ms/step - loss: 0.3949 - accuracy: 0.8503 - val_loss: 0.4724 - val_accuracy: 0.8244\n",
      "Epoch 70/150\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.4010 - accuracy: 0.8470 - val_loss: 0.3602 - val_accuracy: 0.8732\n",
      "Epoch 71/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.4093 - accuracy: 0.8443 - val_loss: 0.3924 - val_accuracy: 0.8572\n",
      "Epoch 72/150\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.3886 - accuracy: 0.8533 - val_loss: 0.3852 - val_accuracy: 0.8618\n",
      "Epoch 73/150\n",
      "118/118 [==============================] - 4s 33ms/step - loss: 0.4105 - accuracy: 0.8417 - val_loss: 0.4316 - val_accuracy: 0.8442\n",
      "Epoch 74/150\n",
      "118/118 [==============================] - 4s 30ms/step - loss: 0.4009 - accuracy: 0.8489 - val_loss: 0.3983 - val_accuracy: 0.8522\n",
      "Epoch 75/150\n",
      "118/118 [==============================] - 4s 30ms/step - loss: 0.3917 - accuracy: 0.8491 - val_loss: 0.5804 - val_accuracy: 0.7902\n",
      "Epoch 76/150\n",
      "118/118 [==============================] - 4s 30ms/step - loss: 0.3967 - accuracy: 0.8487 - val_loss: 0.3415 - val_accuracy: 0.8824\n",
      "Epoch 77/150\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 0.3809 - accuracy: 0.8566 - val_loss: 0.3608 - val_accuracy: 0.8742\n",
      "Epoch 78/150\n",
      "118/118 [==============================] - 3s 30ms/step - loss: 0.3809 - accuracy: 0.8543 - val_loss: 0.3772 - val_accuracy: 0.8696\n",
      "Epoch 79/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.3968 - accuracy: 0.8507 - val_loss: 0.4029 - val_accuracy: 0.8560\n",
      "Epoch 80/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.3748 - accuracy: 0.8597 - val_loss: 0.3864 - val_accuracy: 0.8614\n",
      "Epoch 81/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.4028 - accuracy: 0.8460 - val_loss: 0.3934 - val_accuracy: 0.8522\n",
      "Epoch 82/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.3811 - accuracy: 0.8547 - val_loss: 0.3501 - val_accuracy: 0.8766\n",
      "Epoch 83/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.3732 - accuracy: 0.8603 - val_loss: 0.5802 - val_accuracy: 0.7798\n",
      "Epoch 84/150\n",
      "118/118 [==============================] - 4s 36ms/step - loss: 0.3937 - accuracy: 0.8515 - val_loss: 0.3673 - val_accuracy: 0.8712\n",
      "Epoch 85/150\n",
      "118/118 [==============================] - 4s 38ms/step - loss: 0.3847 - accuracy: 0.8556 - val_loss: 0.6978 - val_accuracy: 0.7596\n",
      "Epoch 86/150\n",
      "118/118 [==============================] - 4s 35ms/step - loss: 0.4065 - accuracy: 0.8432 - val_loss: 0.3384 - val_accuracy: 0.8796\n",
      "Epoch 87/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.3670 - accuracy: 0.8599 - val_loss: 0.3436 - val_accuracy: 0.8796\n",
      "Epoch 88/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.3692 - accuracy: 0.8621 - val_loss: 0.3572 - val_accuracy: 0.8706\n",
      "Epoch 89/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.3766 - accuracy: 0.8581 - val_loss: 0.3823 - val_accuracy: 0.8688\n",
      "Epoch 90/150\n",
      "118/118 [==============================] - 4s 30ms/step - loss: 0.3664 - accuracy: 0.8627 - val_loss: 0.3285 - val_accuracy: 0.8872\n",
      "Epoch 91/150\n",
      "118/118 [==============================] - 4s 30ms/step - loss: 0.3682 - accuracy: 0.8612 - val_loss: 0.3711 - val_accuracy: 0.8646\n",
      "Epoch 92/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.3817 - accuracy: 0.8549 - val_loss: 0.3837 - val_accuracy: 0.8618\n",
      "Epoch 93/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.3737 - accuracy: 0.8581 - val_loss: 0.3730 - val_accuracy: 0.8636\n",
      "Epoch 94/150\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.3820 - accuracy: 0.8563 - val_loss: 0.3911 - val_accuracy: 0.8672\n",
      "Epoch 95/150\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.3676 - accuracy: 0.8613 - val_loss: 0.3792 - val_accuracy: 0.8644\n",
      "Epoch 96/150\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 0.3592 - accuracy: 0.8650 - val_loss: 0.3470 - val_accuracy: 0.8756\n",
      "Epoch 97/150\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 0.3708 - accuracy: 0.8577 - val_loss: 0.3885 - val_accuracy: 0.8634\n",
      "Epoch 98/150\n",
      "118/118 [==============================] - 4s 35ms/step - loss: 0.3654 - accuracy: 0.8621 - val_loss: 0.3465 - val_accuracy: 0.8770\n",
      "Epoch 99/150\n",
      "118/118 [==============================] - 4s 33ms/step - loss: 0.3621 - accuracy: 0.8637 - val_loss: 0.3641 - val_accuracy: 0.8672\n",
      "Epoch 100/150\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 0.3596 - accuracy: 0.8627 - val_loss: 0.3595 - val_accuracy: 0.8748\n",
      "Epoch 101/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.3664 - accuracy: 0.8644 - val_loss: 0.3703 - val_accuracy: 0.8678\n",
      "Epoch 102/150\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.3807 - accuracy: 0.8539 - val_loss: 0.4100 - val_accuracy: 0.8434\n",
      "Epoch 103/150\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.3614 - accuracy: 0.8625 - val_loss: 0.3590 - val_accuracy: 0.8700\n",
      "Epoch 104/150\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.3591 - accuracy: 0.8647 - val_loss: 0.4527 - val_accuracy: 0.8340\n",
      "Epoch 105/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.3700 - accuracy: 0.8625 - val_loss: 0.3632 - val_accuracy: 0.8716\n",
      "Epoch 106/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.3548 - accuracy: 0.8664 - val_loss: 0.3791 - val_accuracy: 0.8660\n",
      "Epoch 107/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.3643 - accuracy: 0.8610 - val_loss: 0.4124 - val_accuracy: 0.8550\n",
      "Epoch 108/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.3602 - accuracy: 0.8642 - val_loss: 0.3553 - val_accuracy: 0.8746\n",
      "Epoch 109/150\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 0.3527 - accuracy: 0.8665 - val_loss: 0.3973 - val_accuracy: 0.8584\n",
      "Epoch 110/150\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.3508 - accuracy: 0.8663 - val_loss: 0.3540 - val_accuracy: 0.8726\n",
      "Epoch 111/150\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.3549 - accuracy: 0.8666 - val_loss: 0.3447 - val_accuracy: 0.8768\n",
      "Epoch 112/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.3399 - accuracy: 0.8715 - val_loss: 0.3664 - val_accuracy: 0.8700\n",
      "Epoch 113/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.3514 - accuracy: 0.8659 - val_loss: 0.3962 - val_accuracy: 0.8554\n",
      "Epoch 114/150\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.3536 - accuracy: 0.8652 - val_loss: 0.3529 - val_accuracy: 0.8778\n",
      "Epoch 115/150\n",
      "118/118 [==============================] - 4s 30ms/step - loss: 0.3486 - accuracy: 0.8681 - val_loss: 0.3379 - val_accuracy: 0.8796\n",
      "Epoch 116/150\n",
      "118/118 [==============================] - 4s 34ms/step - loss: 0.3379 - accuracy: 0.8722 - val_loss: 0.3642 - val_accuracy: 0.8696\n",
      "Epoch 117/150\n",
      "118/118 [==============================] - 4s 36ms/step - loss: 0.3302 - accuracy: 0.8742 - val_loss: 0.3536 - val_accuracy: 0.8726\n",
      "Epoch 118/150\n",
      "118/118 [==============================] - 4s 37ms/step - loss: 0.3285 - accuracy: 0.8772 - val_loss: 0.3723 - val_accuracy: 0.8634\n",
      "Epoch 119/150\n",
      "118/118 [==============================] - 4s 38ms/step - loss: 0.3286 - accuracy: 0.8749 - val_loss: 0.3623 - val_accuracy: 0.8742\n",
      "Epoch 120/150\n",
      "118/118 [==============================] - 4s 34ms/step - loss: 0.3311 - accuracy: 0.8757 - val_loss: 0.3350 - val_accuracy: 0.8840\n",
      "Epoch 121/150\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.3432 - accuracy: 0.8700 - val_loss: 0.3577 - val_accuracy: 0.8700\n",
      "Epoch 122/150\n",
      "118/118 [==============================] - 4s 30ms/step - loss: 0.3409 - accuracy: 0.8714 - val_loss: 0.3583 - val_accuracy: 0.8776\n",
      "Epoch 123/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.3357 - accuracy: 0.8751 - val_loss: 0.4056 - val_accuracy: 0.8530\n",
      "Epoch 124/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.3203 - accuracy: 0.8782 - val_loss: 0.3217 - val_accuracy: 0.8896\n",
      "Epoch 125/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.3195 - accuracy: 0.8776 - val_loss: 0.3865 - val_accuracy: 0.8608\n",
      "Epoch 126/150\n",
      "118/118 [==============================] - 4s 30ms/step - loss: 0.3162 - accuracy: 0.8791 - val_loss: 0.5205 - val_accuracy: 0.8102\n",
      "Epoch 127/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.3167 - accuracy: 0.8826 - val_loss: 0.3334 - val_accuracy: 0.8894\n",
      "Epoch 128/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.3085 - accuracy: 0.8853 - val_loss: 0.3923 - val_accuracy: 0.8678\n",
      "Epoch 129/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.3291 - accuracy: 0.8792 - val_loss: 0.3629 - val_accuracy: 0.8702\n",
      "Epoch 130/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.3113 - accuracy: 0.8815 - val_loss: 0.3369 - val_accuracy: 0.8826\n",
      "Epoch 131/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.3056 - accuracy: 0.8807 - val_loss: 0.3579 - val_accuracy: 0.8798\n",
      "Epoch 132/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.3127 - accuracy: 0.8828 - val_loss: 0.3460 - val_accuracy: 0.8830\n",
      "Epoch 133/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.2972 - accuracy: 0.8886 - val_loss: 0.3444 - val_accuracy: 0.8822\n",
      "Epoch 134/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.3140 - accuracy: 0.8851 - val_loss: 0.3332 - val_accuracy: 0.8888\n",
      "Epoch 135/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.3018 - accuracy: 0.8864 - val_loss: 0.4119 - val_accuracy: 0.8496\n",
      "Epoch 136/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.3118 - accuracy: 0.8829 - val_loss: 0.3551 - val_accuracy: 0.8770\n",
      "Epoch 137/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.3076 - accuracy: 0.8842 - val_loss: 0.3402 - val_accuracy: 0.8826\n",
      "Epoch 138/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.3070 - accuracy: 0.8863 - val_loss: 0.3878 - val_accuracy: 0.8590\n",
      "Epoch 139/150\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 0.3267 - accuracy: 0.8753 - val_loss: 0.3621 - val_accuracy: 0.8732\n",
      "Epoch 140/150\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 0.2987 - accuracy: 0.8872 - val_loss: 0.3704 - val_accuracy: 0.8736\n",
      "Epoch 141/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.2831 - accuracy: 0.8930 - val_loss: 0.3767 - val_accuracy: 0.8720\n",
      "Epoch 142/150\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 0.2904 - accuracy: 0.8903 - val_loss: 0.3671 - val_accuracy: 0.8704\n",
      "Epoch 143/150\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 0.2711 - accuracy: 0.8996 - val_loss: 0.3585 - val_accuracy: 0.8766\n",
      "Epoch 144/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.2833 - accuracy: 0.8954 - val_loss: 0.3935 - val_accuracy: 0.8602\n",
      "Epoch 145/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.3085 - accuracy: 0.8821 - val_loss: 0.3483 - val_accuracy: 0.8772\n",
      "Epoch 146/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.2901 - accuracy: 0.8904 - val_loss: 0.3475 - val_accuracy: 0.8774\n",
      "Epoch 147/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.2696 - accuracy: 0.8987 - val_loss: 0.3377 - val_accuracy: 0.8866\n",
      "Epoch 148/150\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.2775 - accuracy: 0.8948 - val_loss: 0.4198 - val_accuracy: 0.8576\n",
      "Epoch 149/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.2724 - accuracy: 0.8955 - val_loss: 0.3745 - val_accuracy: 0.8694\n",
      "Epoch 150/150\n",
      "118/118 [==============================] - 3s 28ms/step - loss: 0.2798 - accuracy: 0.8951 - val_loss: 0.3748 - val_accuracy: 0.8738\n",
      "LSTM test accuracy: 0.8737999796867371\n",
      "epoch:150\n",
      "[[2355   47  110   61  122   96   68   49   92]\n",
      " [  42 1457    0    0    0    0    1    0    0]\n",
      " [   7    0 1489    0    4    0    0    0    0]\n",
      " [  84   23    0 1288    0    0    0  105    0]\n",
      " [   5    0    4    0 1455    0    0    0   36]\n",
      " [  26    0    0    0    0 1471    0    3    0]\n",
      " [  64    1    0    0    5    0 1356    0   74]\n",
      " [  45    0    0  100    0    9    0 1346    0]\n",
      " [   4    0    1    0  207    0    0    1 1287]] \n",
      "\n",
      " [[728  25  60  20  52  34  26  22  33]\n",
      " [ 22 478   0   0   0   0   0   0   0]\n",
      " [  4   0 493   0   3   0   0   0   0]\n",
      " [ 46  15   0 409   0   0   0  30   0]\n",
      " [  9   0  12   0 465   0   0   0  14]\n",
      " [ 22   0   0   0   0 477   0   1   0]\n",
      " [ 49   0   1   0   0   0 424   0  26]\n",
      " [ 31   0   0  15   0   6   0 448   0]\n",
      " [  5   0   0   0  46   0   2   0 447]]\n"
     ]
    }
   ],
   "source": [
    "mnist_lstm_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
